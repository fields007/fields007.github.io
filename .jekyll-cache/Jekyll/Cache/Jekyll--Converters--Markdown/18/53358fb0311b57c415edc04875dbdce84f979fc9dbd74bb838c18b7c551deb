I"£ﬂ<h1 id="what-is-rsa">what is RSA?</h1>
<p><a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)">RSA</a> is a <em>public-key</em>, or <em>asymmetric</em>, encryption algorithm.
In contrast to <em>symmetric</em> algorithms, like <a href="https://en.wikipedia.org/wiki/Data_Encryption_Standard">DES</a> and
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>, which use the same key for both encryption and
decryption, RSA employs two distinct keys: a <strong>public</strong> key used to encrypt data, and a <strong>private key</strong> used to
decrypt whatever was encrypted with the public one. The beauty of public-key encryption is that the parties involved
never need to exchange a master key, meaning that communications can be securely encrypted without any prior contact.</p>

<p>Public-key encryption was proposed by <a href="https://en.wikipedia.org/wiki/Whitfield_Diffie">Whitfield Diffie</a> and <a href="https://en.wikipedia.org/wiki/Martin_Hellman">Martin
Hellman</a> in ‚Äò76, while RSA itself was patented in ‚Äò77 by <a href="https://en.wikipedia.org/wiki/Ron_Rivest">Ron
<strong>R</strong>ivest</a>, <a href="https://en.wikipedia.org/wiki/Adi_Shamir">Adi <strong>S</strong>hamir</a>, and
<a href="https://en.wikipedia.org/wiki/Leonard_Adleman">Leonard <strong>A</strong>dleman</a>, who then went on to found a
cybersecurity <a href="https://en.wikipedia.org/wiki/RSA_Security">company</a> of the same name ‚Äì confusing, but great PR!</p>

<p><img src="/data/rsa/rivest_shamir_adleman.png" alt="Rivest, Shamir, and Adleman" /></p>

<p><a href="https://en.wikipedia.org/wiki/Clifford_Cocks">Clifford Cocks</a>, an English cryptographer, arrived at a similar
algorithm in ‚Äò73 while working for British intelligence at
<a href="https://en.wikipedia.org/wiki/Government_Communications_Headquarters">GHCQ</a>, but his work wasn‚Äôt declassified until
1998 due to its sensitivity. Forty years later, RSA underpins SSL certification, SSH handshakes, and lots more.</p>

<p>In this post, we‚Äôll implement RSA, but we‚Äôll very much take the long way around while doing so. The algorithm
introduces a number of interesting problems, like finding greatest common divisors, performing modular exponentiation,
computing modular inverses, and generating random prime numbers, each of which we‚Äôll thoroughly explore and derive
solutions to (many of these won‚Äôt be immediately clear, so we‚Äôll formally prove them as we go). Note that we won‚Äôt
prove RSA itself ‚Äì I might add that as an extension to the article at some point in the future.</p>

<h1 id="math-precursor">math precursor</h1>
<p>\(\def \imod {\text{ mod }}
\def \divs {\text{ } \vert \text{ }}\) The only thing we need to know before diving into RSA is some <a href="https://en.wikipedia.org/wiki/Modular_arithmetic">modular
arithmetic</a>, which is simply arithmetic with the property that
numbers have a maximum value (called the <em>modulus</em>) and wrap around to 0 when they exceed it. When we take a number
\(a \imod b\), we‚Äôre basically taking the remainder of \(\frac{a}{b}\); most programming languages provide this in the
form of a <code class="language-plaintext highlighter-rouge">mod</code> function or <code class="language-plaintext highlighter-rouge">%</code> operator. We‚Äôll see lots of expressions in the form of:</p>

\[a \equiv b \pmod c\]

<p>Here, the \(\equiv\) symbol implies <em>congruence</em>, or that \(a \text{ mod } c\) equals \(b \text{ mod } c\). An
important gotcha is that \(\pmod c\) applies to <em>both</em> sides of the expression, which isn‚Äôt immediately obvious to
anyone used to the modulo operator in the programming sense. Many sources choose to omit the parentheses, simply
writing \(a \equiv b \imod c\), which just compounds the confusion; the clearest notation would probably be something
like \((a \equiv b) \pmod c\). This is extremely important to remember because otherwise, expressions like \(a \equiv 1
\imod b\) won‚Äôt make any sense at all (‚Äúbut if \(1 \imod b\) is equal to 1 for all \(b\) not equal to 1, why not just
write \(a = 1\)?!‚Äù).</p>

<p>Some notes about miscellaneous notation:</p>

<ol>
  <li>\(a \divs b\) means that \(a\) divides, or is a factor of, \(b\)</li>
  <li>range notation is used here and there: \([a, b]\) represents all of the numbers between \(a\) and \(b\) inclusive,
\([a, b)\) includes \(a\) but excludes \(b\), \((a, b)\) excludes both \(a\) <em>and</em> \(b\), etc.</li>
</ol>

<h1 id="how-rsa-works">how RSA works</h1>
<p>RSA revolves around a numeric key-pair, or a mathematically related public and private key. The public key is made
known to the world, which can then use it to encrypt a message, while the private key can be used to decrypt anything
encrypted with the public key. Encrypting and decrypting a message is fairly straightforward, while generating a
key-pair is a more substantial process.</p>

<h1 id="generate-a-key-pair">generate a key-pair</h1>
<p>To generate a public/private key-pair:</p>

<ol>
  <li>generate two (large) random primes, \(p\) and \(q\)</li>
  <li>let \(n = pq\)</li>
  <li>find \(\phi(n)\) (<a href="https://en.wikipedia.org/wiki/Euler's_totient_function">Euler‚Äôs totient</a>), or the number of
integers in the range \([1, n]\) that are coprime with \(n\) ‚Äì that is, have a Greatest Common Divisor (GCD) of 1
with it.</li>
  <li>find a value \(e\) such that \(1 \lt e \lt \phi(n)\) and \(e\) is coprime with \(\phi(n)\); this is your <strong>public
key</strong>.</li>
  <li>find a value \(d\) such that \(de \equiv 1 \pmod{\phi(n)}\) ‚Äì in other words, find the
<a href="https://en.wikipedia.org/wiki/Modular_multiplicative_inverse">multiplicative modular inverse</a> of \(e\) modulo \(\phi(n)\); this is your
<strong>private key</strong>.</li>
</ol>

<p>Though short and concise, the above steps present several complex problems:</p>

<ol>
  <li>generate a large, random prime number; this is probably the most involved, so we‚Äôll save it for last (<strong>step 1</strong>)</li>
  <li>find \(\phi(n)\), where \(n\) is the product of two primes (<strong>step 3</strong>)</li>
  <li>find the GCD of two numbers, which will allow us to find \(e\) (<strong>step 4</strong>)</li>
  <li>find the multiplicative modular inverse of a value, to find \(d\) (<strong>step 4</strong>)</li>
</ol>

<h2 id="example">example</h2>
<p>Before we dive into solving those, let‚Äôs walk through the process of generating a key-pair using some small sample
numbers.</p>

<ol>
  <li>let \(p = 3\) and \(q = 5\)</li>
  <li>
    <script type="math/tex">n = 3 \cdot 5 = 15</script>
  </li>
  <li>\(\phi(15) = 8\) (coprime values are 1, 2, 4, 7, 8, 11, 13, and 14)</li>
  <li>\(e = 3\), because 3 is both less than and coprime with 8</li>
  <li>\(d = 3\), because \(3 \cdot 3 = 9\) and \(9 \equiv 1 \pmod 8\)</li>
</ol>

<p>Easy! Except, of course, we weren‚Äôt dealing with numbers with hundreds of digits ‚Äì that‚Äôs the hard part. :)</p>

<h2 id="finding-phin">finding \(\phi(n)\)</h2>
<p>To compute \(\phi(n)\), we can take advantage of the fact that it‚Äôs composed of two <strong>prime</strong> factors: \(p\) and \(q\).
Thus, the only values with which it shares GCDs that aren‚Äôt 1 must be multiples of either \(p\) or \(q\) (for instance,
\(\gcd(n, 2q) = q\) and \(\gcd(n, 3p) = p\)). There are only \(q\) multiples of \(p\) (\(p, 2p, 3p, \ldots, qp\)) and
\(p\) multiples of \(q\) (\(q, 2q, 3q, \ldots, qp\)) that are less than or equal to \(n\). Thus, there are \(q + p\)
values in the range \([1, n]\) that have a GCD with \(n\) not equal to 1. Note, however, that we double counted \(pq\)
in our list of multiples of \(p\) and \(q\), so in reality it‚Äôs \(p + q - 1\). Thus, \(\phi(n) = \text{total} - (p + q
-1)\), where \(\text{total}\) is the total numbers of values in the range \([1, n]\) ‚Äì that is, \(n\).</p>

\[\phi(n) = n - (p + q - 1) = n - p - q + 1\]

<h2 id="computing-gcds">computing GCDs</h2>
<p>To find the GCD of two numbers, we‚Äôll employ the <a href="https://en.wikipedia.org/?title=Euclidean_algorithm">Euclidean
algorithm</a>:</p>

<ol>
  <li>the GCD of any number and 0 is the absolute value of that number</li>
  <li>the GCD of numbers \(a\) and \(b\) is the GCD of \(b\) and \((a \text{ mod } b)\)</li>
</ol>

<p>or:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">gcd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">gcd</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span> <span class="o">%</span> <span class="n">b</span><span class="p">)</span></code></pre></figure>

<p>Let‚Äôs prove it. Case 1 should be self-explanatory: 0 is technically divisible by any number, even if the quotient
equals 0, so the GCD of 0 and any other number should be that number. We need to be careful and take its absolute
value, however, to account for negative values; the greatest divisor of -5 is 5, after all, not -5, so the
GCD of 0 and -5 must also be 5. Thus, we have to take the absolute value of -5 to arrive at the greatest divisor.</p>

<p>Case 2 is less intuitive (at least for me), and requires proving that \(\gcd(a, b) = \gcd(b, a \imod b)\). Let‚Äôs begin
by creating another variable \(c\):</p>

\[c = a - b\]

<h3 id="prove-gcda-b-divs-c">prove \(\gcd(a, b) \divs c\)</h3>
<p>We first want to prove that the GCD of \(a\) and \(b\) divides \(c\) (or \(\gcd(a, b) \divs c\)). Begin by rewriting
\(a\) and \(b\) as products of their GCD.</p>

\[a = x \cdot \gcd(a, b)\\
b = y \cdot \gcd(a, b)\\\]

<p>\(x\) and \(y\) are just placeholders: we don‚Äôt want to know or care what they equal. Now, plug those into the
definition of \(c\):</p>

\[c = a - b\\
c = x \cdot \gcd(a, b) - y \cdot \gcd(a, b) = (x - y) \gcd(a, b)\\
\therefore \gcd(a, b) \divs c\]

<p>Since we‚Äôve shown that \(c\) is the product of \(\gcd(a, b)\) and another value, it is by definition divisible by
\(\gcd(a, b)\).</p>

<h3 id="prove-gcdb-c-divs-a">prove \(\gcd(b, c) \divs a\)</h3>
<p>Apply the same logic here:</p>

\[b = x \cdot \gcd(b, c)\\
c = y \cdot \gcd(b, c)\\
a = c + b\\
a = x \cdot \gcd(b, c) + y \cdot \gcd(b, c) = (x + y) \gcd(b, c)\\
\therefore \gcd(b, c) \divs a\]

<h3 id="prove-gcda-b--gcdb-a---b">prove \(\gcd(a, b) = \gcd(b, a - b)\)</h3>
<p>We know that, by definition, \(\gcd(a, b) \divs b\), and we‚Äôve proven that \(\gcd(a, b) \divs c\). Thus, \(\gcd(a, b)\)
is a <em>common divisor</em> of both \(b\) and \(c\). That doesn‚Äôt imply that it‚Äôs the least common divisor, greatest, or
anything else: all we know is that it divides both numbers. We <em>do</em> know that there exists a <strong>greatest</strong> common
divisor of \(b\) and \(c\), \(\gcd(b, c)\), so we can conclude that:</p>

\[\gcd(a, b) \le \gcd(b, c)\]

<p>We now re-apply that same reasoning. We know that \(\gcd(b, c) \divs b\) and \(\gcd(b, c) \divs a\). Thus, \(\gcd(b,
c)\) is a common divisor of \(b\) and \(a\). Since we know that the <strong>greatest</strong> common divisor of \(a\) and \(b\) is
\(\gcd(a, b)\), we can conclude that:</p>

\[\gcd(b, c) \le \gcd(a, b)\]

<p>But now we have two almost contradictory conclusions:</p>

\[\gcd(a, b) \le \gcd(b, c)\\
\gcd(b, c) \le \gcd(a, b)\]

<p>The only way these can both be true is if:</p>

\[\gcd(a, b) = \gcd(b, c)\]

<p>So we‚Äôve proven that \(\gcd(a, b) = \gcd(b, a - b)\) (remember, \(c = a - b\)).</p>

<h3 id="prove-gcdb-a---b--gcdb-a-imod-b">prove \(\gcd(b, a - b) = \gcd(b, a \imod b)\)</h3>
<p>First, let‚Äôs assume that \(a &gt; b\), and rewrite it as: \(a = bq + r\) (or \(r = a \imod b\))</p>

<p>Now, we already know that \(\gcd(a, b) = \gcd(b, a - b)\), Since order doesn‚Äôt matter, we can rewrite \(\gcd(b, a -
b)\) as \(\gcd(a - b, b)\). Now, we apply the rule \(\gcd(a, b) = \gcd(b, a - b)\) again.</p>

\[\gcd(a, b) = \gcd(b, a - b) = \gcd(a - b, b)\\
\gcd(a - b, b) = \gcd(b, a - b - b) = \gcd(a - 2b, b)\\
\gcd(a - 2b, b) = \gcd(b, a - 2b - b) = \gcd(a - 3b, b)\\
\gcd(a - 3b, b) = \gcd(b, a - 3b - b) = \gcd(a - 4b, b)\\
\ldots\\
\gcd(a - qb, b) = \gcd(r, b)\]

<p>or:</p>

\[\gcd(a, b) = \gcd(a - b, b) = \gcd(a - 2b, b) = \ldots = \gcd(a - qb, b) = \gcd(r, b)\]

<p>Bingo. We‚Äôve proven Case 2, and completed our proof of the Euclidean Algorithm. Before we move on, we‚Äôll also define a
convenience wrapper for <code class="language-plaintext highlighter-rouge">gcd()</code> that determines whether two numbers are prime:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">coprime</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">gcd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span></code></pre></figure>

<h2 id="finding-modular-inverses">finding modular inverses</h2>
<p>Given a value \(a\) and modulus \(c\), the modular multiplicative inverse of \(a\) is a value \(b\) that satisfies:</p>

\[ab \equiv 1 \pmod c\]

<p>This implies that there exists some value \(d\) for which:</p>

\[ab = 1 + cd\\
ab - cd = 1\]

<p>This turns out to be in the form of <a href="https://en.wikipedia.org/wiki/B%C3%A9zout's_identity">B√©zout‚Äôs identity</a>, which
states that for values \(m\) and \(n\), there exist values \(x\) and \(y\) that satisfy:</p>

\[mx + ny = \gcd(m, n)\]

<p>\(x\) and \(y\), called B√©zout coefficients, can be solved for using the <a href="https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm">Extended Euclidean
algorithm</a> (EEA). \(x\) corresponds to \(b\), or the
modular inverse that we were looking for, while \(y\) can be thrown out once computed. The EEA will also give us the
GCD of \(m\) and \(n\) ‚Äì it is, after all, an extension of the Euclidean algorithm, which we use to find the GCD of
two values. We need to verify that it equals 1, since we make the assume that \(\gcd(m, n) = 1\); if it doesn‚Äôt, \(a\)
has no modular inverse. Since <code class="language-plaintext highlighter-rouge">modular_inverse()</code> is just a wrapper for EEA ‚Äì to be implemented in a function called
<code class="language-plaintext highlighter-rouge">bezout_coefficients()</code> ‚Äì its definition is simple:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">modular_inverse</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">modulus</span><span class="p">):</span>
    <span class="n">coef1</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">gcd</span> <span class="o">=</span> <span class="n">bezout_coefficients</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">modulus</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">coef1</span> <span class="k">if</span> <span class="n">gcd</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">None</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">bezout_coefficients()</code> is a bit tricker:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">bezout_coefficients</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">quotient</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">coef1</span><span class="p">,</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">gcd</span> <span class="o">=</span> <span class="n">bezout_coefficients</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">coef1</span> <span class="o">-</span> <span class="n">quotient</span> <span class="o">*</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">gcd</span></code></pre></figure>

<p>Let‚Äôs see why it works.</p>

<h3 id="the-extended-euclidean-algorithm">the Extended Euclidean algorithm</h3>
<p>How to solve for \(x\) and \(y\)? Bezout‚Äôs Identity states:</p>

\[\gcd(a, b) = ax + by\\\]

<p>or, for \(\gcd(b, a \imod b)\):</p>

\[\gcd(b, a \imod b) = bx' + (a \imod b)y'\\\]

<p>Let‚Äôs simplify:</p>

\[a \imod b = a - \lfloor \frac{a}{b} \rfloor b\]

<p>Here, \(\lfloor \rfloor\) represents the <em>floor</em> function, which floors the result of \(\frac{a}{b}\) to an integer.</p>

\[\gcd(b, a \imod b) = bx' + (a - \lfloor \frac{a}{b} \rfloor b)y' =\\
  bx' + ay' - \lfloor \frac{a}{b} \rfloor by' =\\
  ay' + b(x' - \lfloor \frac{a}{b} \rfloor y')\]

<p>Since we know, by the already proven Euclidean algorithm, that \(\gcd(a, b) = \gcd(b, a \imod b)\), we can write:</p>

\[ax + by = ay' + b(x' - \lfloor \frac{a}{b} \rfloor y')\]

<p>So, \(x = y'\) and \(y = x' - \lfloor \frac{a}{b} \rfloor y'\). But what are \(x'\) and \(y'\)? They‚Äôre the results of
running the EEA on \((b, a \imod b)\)! Classic recursion. In sum:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">bezout_coefficients</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">quotient</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">coef1</span><span class="p">,</span> <span class="n">coef2</span> <span class="o">=</span> <span class="n">bezout_coefficients</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">coef1</span> <span class="o">-</span> <span class="n">quotient</span> <span class="o">*</span> <span class="n">coef2</span></code></pre></figure>

<p>Of course, we need a base case, or we‚Äôll end up recursing <em>ad infinitum</em>. Let‚Äôs take the case of \(b = 0\).</p>

\[ax + by = \gcd(a, b)\\
b = 0\\
ax + 0y = \gcd(a, 0)\\
ax = |a|\\
x = \frac{|a|}{a}\]

<p>So, if \(b = 0\), we set the \(x\) coefficient to 1 if \(a\) is positive and -1 is \(a\) is negative, and set \(y\)
to‚Ä¶ what? If \(b\) is 0, then \(y\) can take on any value. For simplicity‚Äôs sake we‚Äôll choose 0. Our revised
definition looks like:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">bezout_coefficients</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">quotient</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">coef1</span><span class="p">,</span> <span class="n">coef2</span> <span class="o">=</span> <span class="n">bezout_coefficients</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">coef1</span> <span class="o">-</span> <span class="n">quotient</span> <span class="o">*</span> <span class="n">coef2</span></code></pre></figure>

<p>Also note that, since this is simply a more involved version of the Euclidean algorithm (we‚Äôre making recursive calls
to <code class="language-plaintext highlighter-rouge">bezout_coefficients(b, remainder)</code> and have a base case of <code class="language-plaintext highlighter-rouge">b == 0</code>), when we hit the base case, <code class="language-plaintext highlighter-rouge">abs(a)</code> is the
GCD of <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>. Since <code class="language-plaintext highlighter-rouge">modular_inverse()</code> needs to check that the GCD of its two arguments equals 1, we should
return it in addition to the coefficients themselves. Hence, we‚Äôll let it trickle up from our base case into the final
return value:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">bezout_coefficients</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">quotient</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">coef1</span><span class="p">,</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">gcd</span> <span class="o">=</span> <span class="n">bezout_coefficients</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">remainder</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">coef1</span> <span class="o">-</span> <span class="n">quotient</span> <span class="o">*</span> <span class="n">coef2</span><span class="p">,</span> <span class="n">gcd</span></code></pre></figure>

<h2 id="generating-large-random-primes">generating large, random primes</h2>
<p>Here‚Äôs the idea:</p>

<ol>
  <li>generate a large, random, <strong>odd</strong> number \(x\)</li>
  <li>check \(x\) for primality
    <ol>
      <li>if \(x\) prime, return it</li>
      <li>otherwise, increment \(x\) by 2, and return to step <strong>2.)</strong></li>
    </ol>
  </li>
</ol>

<p>Easy enough, except for the bit about testing primality. How to do so efficiently? We‚Äôll turn to the
<a href="https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test">Rabin-Miller</a> algorithm, a probabilistic primality
test which either tells us with absolute certainty that a number is composite, or with high likelihood that it‚Äôs prime.
We‚Äôre fine with a merely probabilistic solution because it‚Äôs <em>fast</em>, since speed is a non-negligible issue due to the
size of the numbers that we‚Äôre dealing with, and also because the chances of a false positive (ie indicating that a
number is prime when it‚Äôs actually composite) are astronomically low after even only a few iterations of the test.</p>

<h3 id="rabin-miller-primality-test">Rabin-Miller primality test</h3>
<p>The Rabin-Miller test relies on the below two assumptions (just accept that they‚Äôre true for now, and we‚Äôll prove them
later on). If \(p\) is a prime number:</p>

<ol>
  <li>\(a ^ {p - 1} \equiv 1 \pmod p\) for any \(a\) not divisible by \(p\)</li>
  <li>for any \(x\) that satisfies \(x ^ 2 \equiv 1 \pmod p\), \(x\) <strong>must</strong> equal ¬±1</li>
</ol>

<p>Using these, you can test a value \(n\) for compositeness like so (note that we return <code class="language-plaintext highlighter-rouge">true</code>/<code class="language-plaintext highlighter-rouge">false</code> to indicate
definite compositeness/probable primality respectively):</p>

<ol>
  <li>pick a random value \(a\) in the range \([2, n - 1]\)</li>
  <li>use <strong>assumption 1</strong> to assert that \(a ^ {n - 1} \equiv 1 \pmod n\)); if it‚Äôs not, return <code class="language-plaintext highlighter-rouge">true</code></li>
  <li>if \(a\) has an integer square root, let \(a' = \sqrt a\); otherwise, return <code class="language-plaintext highlighter-rouge">false</code></li>
  <li>since \(a' ^ 2 \equiv 1 \pmod n\), we can use <strong>assumption 2</strong> to assert that \(a' \equiv \pm 1 \pmod n\); if not,
return <code class="language-plaintext highlighter-rouge">true</code></li>
  <li>otherwise, repeat steps 3-4, taking the square root of \(a'\), and the square root of that, and so on, until you
hit a value that doesn‚Äôt have an integer square root.</li>
  <li>if you haven‚Äôt already returned anything, you‚Äôve satisfied assumptions <strong>1</strong> and <strong>2</strong> for all testable cases and
can return <code class="language-plaintext highlighter-rouge">false</code>.</li>
</ol>

<p>In sum, we return <code class="language-plaintext highlighter-rouge">true</code> if we‚Äôve confirmed that \(a\) is a <em>witness to the compositeness</em> of \(n\), and <code class="language-plaintext highlighter-rouge">false</code> if
\(a\) does <em>not</em> prove that \(n\) is composite ‚Äì transitively, there is a high chance that \(n\) is prime, but we can
only be more sure by running more such tests. While the above steps serve as a good verbal description of the
algorithm, we‚Äôll have to slightly modify them to convert the algorithm into real code.</p>

<p>We need to implement a function <code class="language-plaintext highlighter-rouge">is_witness()</code>, which checks whether a random value is a witness to the compositeness
of our prime candidate, \(n\).</p>

<ol>
  <li>write \(n - 1\) in the form \(2 ^ s d\). \(n=73\), for instance, would yield \(s=3\) and \(d=9\), since \(73 - 1 =
72 = 2 ^ 3 \cdot 9\).</li>
  <li>pick a random value \(a\) in the range \([2, n - 1]\). We‚Äôll check whether this is a witness for \(n\).</li>
  <li>let \(x = a ^ d \imod n\)</li>
  <li>if \(x \equiv \pm 1 \pmod n\), then return <code class="language-plaintext highlighter-rouge">false</code></li>
  <li>repeat \(s - 1\) times:
    <ol>
      <li>let \(x = x ^ 2 \imod n\)</li>
      <li>if \(x = 1\), return <code class="language-plaintext highlighter-rouge">true</code></li>
      <li>if \(x = n - 1\), return <code class="language-plaintext highlighter-rouge">false</code></li>
    </ol>
  </li>
  <li>if we haven‚Äôt returned yet, return <code class="language-plaintext highlighter-rouge">true</code></li>
</ol>

<p>These steps seem quite a bit different from before, but in reality, they‚Äôre exactly the same and just operating in
reverse. We start with a value that doesn‚Äôt have an integer square root, and square it until we hit \(a ^ {n - 1}\).
Why did we bother decomposing \(n - 1\) into the form of \(2 ^ s d\)? Well, it allows us to rewrite \(a ^ {n - 1}\)
as \(a ^ {2 ^ s d}\), and now we know <strong>exactly</strong> how many times we can take square roots before we hit a value that
isn‚Äôt reducible any further ‚Äì in this case, \(a ^ d\).</p>

\[a_1 = \sqrt{a ^ {2 ^ s d}} = (a ^ {2 ^ s d}) ^ \frac{1}{2} = a ^ {\frac{1}{2} \cdot 2 \cdot 2 ^ {s - 1} d} =
  a ^ {2 ^ {s - 1} d}\\
a_2 = \sqrt{a ^ {2 ^ {s - 1} d}} = (a ^ {2 ^ {s - 1} d}) ^ \frac{1}{2} = a ^ {\frac{1}{2} \cdot 2 \cdot 2 ^ {s - 2} d}
  = a ^ {2 ^ {s - 2} d}\\
\ldots\\
a_{last} = a ^ d\]

<p>So, if we start with \(a ^ d\) and square it, we‚Äôll get \(a ^ {2d}\), then \(a ^ {2 ^ 2 d}\), then \(a ^ {2 ^ 3 d}\),
and ultimately \(a ^ {2 ^ s d}\), or \(a ^ {n - 1}\). What‚Äôs the advantage of starting from the non-reducible value and
squaring it, rather than the reducible value and taking its square roots? It sometimes allows us to short-circuit the
process. For instance, as we iterate through the squares of \(a ^ d\), if we find an occurrence of -1, we know that
we‚Äôll get 1 when we square it, and 1 when we square that, and keep on getting 1s until we stop iterating. As a
consequence, we know that we won‚Äôt find any failing conditions, and can exit early by returning <code class="language-plaintext highlighter-rouge">false</code> (<strong>step 5.3</strong>).
The same goes for <strong>step 4</strong>: if \(a ^ d \equiv \pm 1 \pmod n\), we know that each of the following squares will equal
1, so we immediately return <code class="language-plaintext highlighter-rouge">false</code>.</p>

<p>The failing conditions ‚Äì ie those that cause the algorithm to return <code class="language-plaintext highlighter-rouge">true</code> ‚Äì might not be immediately clear. In
<strong>5.2</strong>, we know that, if \(x = 1\), we‚Äôve violated <strong>assumption 2</strong>, because that implies that the previous value of
\(x\) was not equivalent to \(\pm 1 \pmod n\). Wait, why? Because if it were equal to -1, we would‚Äôve already returned
via <strong>5.3</strong> in the previous iteration, and if it were \(1\), then we would‚Äôve returned either from <strong>5.3</strong> in an
earlier iteration still or <strong>4</strong> at the very beginning. We also return <code class="language-plaintext highlighter-rouge">true</code> when we hit <strong>6</strong>, because we know that
by that point, if <strong>assumption 1</strong> is:</p>

<ol>
  <li>true, and \(x = a ^ {n - 1} \equiv 1 \pmod n\), then the previous value of \(x\) can‚Äôt be either 1 or -1 because
we would already have returned via either <strong>4</strong> or <strong>5.3</strong>.</li>
  <li>false, then by definition \(n\) can‚Äôt be prime, since the assumption <em>must</em> hold true for prime \(n\)</li>
</ol>

<p>Finally, we simply repeat the <code class="language-plaintext highlighter-rouge">is_witness()</code> test \(k = 5\) times. Here‚Äôs the final implementation:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">is_prime</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>

    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">False</span>

    <span class="n">s</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">decompose_to_factors_of_2</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_witness</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">modular_power</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]:</span>
            <span class="k">return</span> <span class="bp">False</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">modular_power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">True</span>

            <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">False</span>

        <span class="k">return</span> <span class="bp">True</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">is_witness</span><span class="p">(</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">False</span>

    <span class="k">return</span> <span class="bp">True</span>

<span class="k">def</span> <span class="nf">decompose_to_factors_of_2</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">num</span>

    <span class="k">while</span> <span class="n">d</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">//=</span> <span class="mi">2</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">s</span><span class="p">,</span> <span class="n">d</span></code></pre></figure>

<p>Note that we‚Äôve introduced a currently undefined function, <code class="language-plaintext highlighter-rouge">modular_power()</code>. The problem with computing \(a ^ d \imod
n\) and \(x ^ 2 \imod n\) is that \(a\), \(d\), \(x\), and \(n\) are <strong>HUGE</strong>. Simply running <code class="language-plaintext highlighter-rouge">(a ** d) % n</code> would be
asking for trouble. Fortunately, there are efficient ways of performing modular exponentiation, and we‚Äôll implement
one such method in the <code class="language-plaintext highlighter-rouge">modular_power()</code> function later in this article. Now, we need to actually prove the two
assumptions that we base Rabin-Miller on.</p>

<h4 id="euclids-lemma">Euclid‚Äôs lemma</h4>
<p>‚Ä¶but before we do so, we need to prove <a href="https://en.wikipedia.org/wiki/Euclid's_lemma">Euclid‚Äôs Lemma</a>, since both of
the following proofs depend on it. It states that if \(p\) is relatively prime to \(a\) and \(p \divs ab\), then \(p
\divs b\). We‚Äôll prove it using Bezout‚Äôs Identity. The GCD of \(a\) and \(p\) is 1, so there must exist \(x\) and \(y\)
that satisfy:</p>

\[ax + py = 1\]

<p>Multiply both sides by \(b\):</p>

\[abx + pby = b\]

<p>\(abx\) is divisible by \(p\) (because it‚Äôs divisible by \(ab\), which is divisible by \(p\) according to the lemma‚Äôs
requisite), and \(pby\) is by definition divisible by \(p\), so \(b\) must be divisible by \(p\) too.</p>

<h4 id="proof-of-assumption-1">proof of assumption 1</h4>
<p>Our first assumption was that for a prime \(p\), \(a ^ {p - 1} \equiv 1 \pmod p\) for any \(a\) <strong>not divisible by
\(p\)</strong>. This is better known as <a href="https://en.wikipedia.org/wiki/Fermat's_little_theorem">Fermat‚Äôs Little Theorem</a>. To
prove it, begin by multiplying all of the numbers in the range \([1, p)\) by \(a\):</p>

\[a, 2a, 3a, \ldots, (p - 1) a\]

<p>We make two observations:</p>

<ol>
  <li>
    <p>given two values \(x\) and \(y\), \(ax \equiv ay \pmod p\) is equivalent to \(x \equiv y \pmod p\) (we effectively
divide out \(a\)). We can prove this by rewriting \(ax \equiv ay \pmod p\) as \(ax - ay \equiv 0 \pmod p\), which
implies that \(p \divs ax - ay\), or \(p \divs a(x - y)\). By Euclid‚Äôs Lemma, since \(p\) and \(a\) are coprime
(reminder: this is a criterion of Fermat‚Äôs Little Theorem), \(p \divs x - y\), which means we can write \(x - y
\equiv 0 \pmod p\), or \(x \equiv y \pmod p\).</p>
  </li>
  <li>
    <p>when each of its elements is simplified in \(\imod p\), the above sequence is simply a rearrangement of \(1, 2,
\ldots, p - 1\). This is true because, firstly, its values all lie in the range \([1, p)\) ‚Äì none can equal 0
since \(p\) shares no factors other than 1 with either \(a\) or any value in \(1, 2, \ldots, p - 1\) due to its
primeness. The trick now is to realize that, if we have two distinct values \(x\) and \(y\), and know that \(ax
\equiv ay \pmod p\), then by the previous observation we can ‚Äúdivide out \(a\)‚Äù and have \(x \equiv y \pmod p\).
If \(x\) and \(y\) were two values chosen from the \(1, \ldots, p - 1\) sequence, we‚Äôd know that they‚Äôre all less
than \(p\), and can thus remove the \(\imod p\) from the expression, leaving us with: \(x = y\). In conclusion,
the only way to satisfy \(ax \equiv ay \imod p\) is to have \(x\) be the same item as \(y\), and that means that
the distinct values in \(a, \ldots, (p - 1) a\) map to distinct values in \(1, \ldots, p - 1\).</p>
  </li>
</ol>

<p>By <strong>observation 1</strong>:</p>

\[a \cdot 2a \cdot \ldots \cdot (p - 1) a \equiv 1 \cdot 2 \cdot \ldots \cdot (p - 1) \pmod p\\
a ^ {p - 1} (p - 1)! \equiv (p - 1)! \pmod p\]

<p>By <strong>observation 2</strong>, we can cancel out each of the factors of \((p - 1)!\) from both sides of the expressions (after
all, \(p\) is prime and all of the factors of \((p - 1)!\) are less than it, so it‚Äôs coprime with all of them), which
leaves us with:</p>

\[a ^ {p - 1} \equiv 1 \pmod p\]

<p>QED.</p>

<h4 id="proof-of-assumption-2">proof of assumption 2</h4>
<p>We now prove assumption 2: if \(p\) is prime and \(x ^ 2 \equiv 1 \pmod p\), \(x\) must equal \(\pm 1 \imod p\). First,
for greater clarity later on, we can rewrite our conclusion as: \(p\) must divide either \(x - 1\) or \(x + 1\). Now,
if \(x ^ 2 \equiv 1 \pmod p\), then:</p>

\[x ^ 2 - 1 \equiv 0 \pmod p\\
p \divs x ^ 2 - 1\\
p \divs (x - 1)(x + 1)\]

<p>If \(p\) divides \(x - 1\), then:</p>

\[x - 1 \equiv 0 \pmod p\\
x \equiv 1 \pmod p\]

<p>and we‚Äôve proven our conclusion. What if \(p\) <em>doesn‚Äôt</em> divide \(x - 1\)? We can then leverage Euclid‚Äôs Lemma: if
\(p\) is relatively prime to \(a\) and \(p \divs ab\), then \(p \divs b\). We know that \(p\) is prime and doesn‚Äôt
divide \(x - 1\), so it‚Äôs relatively prime to \(x - 1\), and we know that it divides \((x - 1)(x + 1)\). As a result,
it has to divide \(x + 1\), which implies that: \(x \equiv -1 \pmod p\). Again, we‚Äôve proven our conclusion, and thus
proven assumption 2.</p>

<h3 id="applying-rabin-miller">applying Rabin-Miller</h3>
<p>Now that we‚Äôve implemented Rabin-Miller, creating a large, random prime is almost trivial:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_random_prime</span><span class="p">(</span><span class="n">num_bits</span><span class="p">):</span>
    <span class="n">lower_bound</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">num_bits</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">upper_bound</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">num_bits</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">guess</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="n">lower_bound</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">guess</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">guess</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">is_prime</span><span class="p">(</span><span class="n">guess</span><span class="p">):</span>
        <span class="n">guess</span> <span class="o">+=</span> <span class="mi">2</span>

    <span class="k">return</span> <span class="n">guess</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">num_bits</code> parameter is a bit of a weird way of specifying the desired size of the prime, but it‚Äôll make sense
since we usually want to create RSA keys of a specific bit-length (more on this later on).</p>

<h2 id="wrapping-it-all-up">wrapping it all up</h2>
<p>At long last, we can define our <code class="language-plaintext highlighter-rouge">create_key_pair()</code> function.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">create_key_pair</span><span class="p">(</span><span class="n">bit_length</span><span class="p">):</span>
    <span class="n">prime_bit_length</span> <span class="o">=</span> <span class="n">bit_length</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">get_random_prime</span><span class="p">(</span><span class="n">prime_bit_length</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">get_random_prime</span><span class="p">(</span><span class="n">prime_bit_length</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">q</span>
    <span class="n">totient</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">q</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">e_candidate</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">totient</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">e_candidate</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">e_candidate</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">coprime</span><span class="p">(</span><span class="n">e_candidate</span><span class="p">,</span> <span class="n">totient</span><span class="p">):</span>
            <span class="n">e</span> <span class="o">=</span> <span class="n">e_candidate</span>
            <span class="k">break</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">modular_inverse</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">totient</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">e</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">n</span></code></pre></figure>

<p>The only thing that requires explanation is this <code class="language-plaintext highlighter-rouge">bit_length</code> business. The idea here is that we generally want to
create RSA keys of a certain bit-length (1024 and 2048 are common values), so we pass in a parameter specifying the
length. To make sure that \(n\) has a bit-length approximately equal to <code class="language-plaintext highlighter-rouge">bit_length</code>, we need to make sure that the
primes \(p\) and \(q\) that we use to create it have a bit length of <code class="language-plaintext highlighter-rouge">bit_length / 2</code>, since multiplying two \(n\)-bit
numbers yields an approximately \(2n\)-bit value. How come? The number of bits in a positive integer \(n\) is
\(\lfloor \log_2 n \rfloor + 1\), so the number of bits in \(n ^ 2\) is \(\lfloor \log_2 n ^ 2\rfloor + 1\). According
to the <a href="http://www.rapidtables.com/math/algebra/logarithm/Logarithm_Rules.htm#power rule">logarithm power rule</a>, we can
rewrite \(\log{a ^ b}\) as \(b \cdot \log a\), so the bit length equals \(\lfloor 2\log_2 n \rfloor + 1\). In other
words, \(n ^ 2\) has roughly twice as many bits as \(n\).</p>

<h1 id="encryptdecrypt-messages">encrypt/decrypt messages</h1>
<p>In comparison to generating keys, encrypting and decrypting data with them is mercifully simple.</p>

<ol>
  <li>encrypt a message \(m\) with public key \(e\) and modulus \(n\): \(m ^ e \imod n\)</li>
  <li>decrypt a message \(c\) with private key \(d\) and modulus \(n\): \(c ^ d \imod n\)</li>
</ol>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">encrypt</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">modular_power</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">decrypt</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">modular_power</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span></code></pre></figure>

<p>So, what‚Äôs <code class="language-plaintext highlighter-rouge">modular_power()</code>? The problem with the encryption and decryption operations, which look
deceptively trivial, is that all of the values involved are big. Really, really big. As a result, naively solving \(a ^
b \imod c\) by simply resolving \(a ^ b\) and then simplifying that modulo \(c\) is a no-go. Fortunately, there are
more efficient ways of performing <a href="https://en.wikipedia.org/wiki/Modular_exponentiation">modular exponentiation</a>, like
exponentiation by squaring.</p>

<h2 id="exponentiation-by-squaring">exponentiation by squaring</h2>
<p>When trying to solve \(a ^ b \imod c\), begin by representing \(b\) in binary form:</p>

\[b = 2 ^ {n - 1} bit_{n - 1} + 2 ^ {n - 2} bit_{n - 2} + \ldots + 2 bit_1 + bit_0\]

<p>where \(n\) is the total number of bits in \(b\), and \(bit\) represents the value of each bit ‚Äì either 0 or 1. Now,
rewrite the original expression:</p>

\[a ^ b \imod c =\\
a ^ {2 ^ {n - 1} bit_{n - 1} + 2 ^ {n - 2} bit_{n - 2} + \ldots + 2 bit_1 + bit_0} \imod c =\\
a ^ {2 ^ {n - 1} bit_{n - 1}} \cdot a ^ { 2 ^ {n - 2} bit_{n - 2}} \cdot \ldots \cdot a ^ {2 bit_1} \cdot a ^ {bit_0}
  \imod c\\\]

<p>For illustrative purposes, let‚Äôs temporarily remove the \(bit\) factor from each exponent, which leaves us with:</p>

\[a ^ {2 ^ {n - 1}} \cdot a ^ { 2 ^ {n - 2}} \cdot \ldots \cdot a ^ {2} \cdot a \imod c\]

<p>It‚Äôs now obvious that each factor is a square of the one that precedes it: \(a ^ {2}\) is the square of \(a\),
\(a ^ {2 ^ {n - 1}}\) is the square of \(a ^ { 2 ^ {n - 2}}\), etc. If we were to programmatically solve the
expression, we could maintain a variable, say <code class="language-plaintext highlighter-rouge">accumulator</code>, that we‚Äôd initialize to \(a\), and square from
factor to factor to avoid recomputing \(a ^ {\text{big exponent}}\) every time. Now, let‚Äôs reintroduce \(bit\):</p>

\[a ^ {2 ^ {n - 1} bit_{n - 1}} \cdot a ^ { 2 ^ {n - 2} bit_{n - 2}} \cdot \ldots \cdot a ^ {2 bit_1} \cdot a ^ {bit_0}
  \imod c\\\]

<p>The good thing is that \(bit\) has a limited set of possible values: just 0 and 1! Any value in the form
\(a ^ {2 ^ p bit}\) ‚Äì that is, all of the above factors ‚Äì evaluates to \(a ^ {2 ^ p}\) when \(bit = 1\),
and \(a ^ 0\), or 1, when \(bit = 0\). In other words, the value of \(bit\) only controls whether or not we multiply
one of the factors into the accumulator that‚Äôll become our ultimate result (since if \(bit = 0\), we‚Äôll just end up
multiplying in 1, which means we shouldn‚Äôt even bother). Thus, <code class="language-plaintext highlighter-rouge">modular_power()</code> might look something like this:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">modular_power</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">exp</span><span class="p">,</span> <span class="n">modulus</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">while</span> <span class="n">exp</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">exp</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">*</span> <span class="n">base</span>
        <span class="n">exp</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="n">base</span> <span class="o">=</span> <span class="n">base</span> <span class="o">**</span> <span class="mi">2</span>

    <span class="k">return</span> <span class="n">result</span> <span class="o">%</span> <span class="n">modulus</span></code></pre></figure>

<p>But we still haven‚Äôt addressed the issue of multiplying huge numbers by huge numbers, and this version of
<code class="language-plaintext highlighter-rouge">modular_power()</code> doesn‚Äôt perform much better than <code class="language-plaintext highlighter-rouge">(base ** exp) % modulus</code> (in fact, after some spot checking, it
appears to be much slower!). We can address that by taking advantage of the following property of modular
multiplication:</p>

\[xy \imod z = (x \imod z)(y \imod z) \imod z\]

<p>We can prove it by rewriting \(x\) and \(y\) in terms of \(z\):</p>

\[x = q_x z + r_x\\
y = q_y z + r_y\]

<p>and substituting that into the original expression:</p>

\[xy \imod z =\\
(q_x z + r_x) (q_y z + r_y) \imod z =\\
q_x q_y z ^ 2 + q_x z r_y + r_x q_y z + r_x r_y \imod z =\\
z(q_x q_y z + q_x r_y + r_x q_y) + r_x r_y \imod z =\\
r_x r_y \imod z\]

<p>We‚Äôre able to remove the entire chunk of the expression that gets multiplied by \(z\) because it‚Äôs by definition
divisible by \(z\), meaning that, taken \(\imod z\), it would equal 0, and wouldn‚Äôt contribute anything to the sum.
Thus, \(xy \imod z\) equals \(r_x r_y \imod z\), or \((x \imod z)(y \imod z) \imod z\).</p>

<p>Using that, we can make the following adjustment to our initial implementation:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">modular_power</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">exp</span><span class="p">,</span> <span class="n">modulus</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">base</span> <span class="o">%=</span> <span class="n">modulus</span>

    <span class="k">while</span> <span class="n">exp</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">exp</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">result</span> <span class="o">*</span> <span class="n">base</span><span class="p">)</span> <span class="o">%</span> <span class="n">modulus</span>
        <span class="n">exp</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span>
        <span class="n">base</span> <span class="o">=</span> <span class="p">(</span><span class="n">base</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">%</span> <span class="n">modulus</span>

    <span class="k">return</span> <span class="n">result</span></code></pre></figure>

<p>We‚Äôre now taking <code class="language-plaintext highlighter-rouge">% modulus</code> in a bunch of places, which is valid due to the above property and prevents the value of
both <code class="language-plaintext highlighter-rouge">result</code> and <code class="language-plaintext highlighter-rouge">base</code> from growing out of control.</p>

<p>That tops off our implementation of RSA. <a href="/data/rsa/rsa.py">Here‚Äôs</a> the entire source file.</p>

<h1 id="acknowledgements">acknowledgements</h1>
<p>I wouldn‚Äôt have been able to present most of the proofs in this article without help from the following sources. One of
the key motivations for gathering them all in one post is that, as I tried to understand all of the moving parts of
RSA, I needed to sift through <em>a lot</em> of material to find accessible and satisfactory explanations:</p>

<ul>
  <li><a href="https://www.khanacademy.org/computing/computer-science/cryptography/modarithmetic/a/the-euclidean-algorithm">the Euclidean algorithm</a></li>
  <li><a href="http://pages.pacificcoast.net/~cazelais/222/xeuclid.pdf">the Extended Euclidean algorithm</a></li>
  <li><a href="https://en.wikipedia.org/?title=Proofs_of_Fermat%27s_little_theorem">Fermat‚Äôs Little Theorem</a></li>
  <li><a href="http://home.sandiego.edu/~dhoffoss/teaching/cryptography/10-Rabin-Miller.pdf">Rabin-Miller test</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Modular_exponentiation#Right-to-left_binary_method">exponentiation by squaring</a></li>
</ul>
:ET